{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbf68b26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T08:58:02.982460Z",
     "iopub.status.busy": "2025-08-26T08:58:02.981488Z",
     "iopub.status.idle": "2025-08-26T08:58:25.757008Z",
     "shell.execute_reply": "2025-08-26T08:58:25.755577Z"
    },
    "papermill": {
     "duration": 22.781846,
     "end_time": "2025-08-26T08:58:25.759144",
     "exception": false,
     "start_time": "2025-08-26T08:58:02.977298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: scikit-learn 1.2.2\r\n",
      "Uninstalling scikit-learn-1.2.2:\r\n",
      "  Successfully uninstalled scikit-learn-1.2.2\r\n",
      "Found existing installation: imbalanced-learn 0.13.0\r\n",
      "Uninstalling imbalanced-learn-0.13.0:\r\n",
      "  Successfully uninstalled imbalanced-learn-0.13.0\r\n",
      "Collecting scikit-learn==1.4.0\r\n",
      "  Downloading scikit_learn-1.4.0-1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\r\n",
      "Collecting imbalanced-learn==0.11.0\r\n",
      "  Downloading imbalanced_learn-0.11.0-py3-none-any.whl.metadata (8.3 kB)\r\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.4.0) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.4.0) (1.15.3)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.4.0) (1.5.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.4.0) (3.6.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.19.5->scikit-learn==1.4.0) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.19.5->scikit-learn==1.4.0) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.19.5->scikit-learn==1.4.0) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.19.5->scikit-learn==1.4.0) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.19.5->scikit-learn==1.4.0) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.19.5->scikit-learn==1.4.0) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0,>=1.19.5->scikit-learn==1.4.0) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0,>=1.19.5->scikit-learn==1.4.0) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0,>=1.19.5->scikit-learn==1.4.0) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0,>=1.19.5->scikit-learn==1.4.0) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0,>=1.19.5->scikit-learn==1.4.0) (2024.2.0)\r\n",
      "Downloading scikit_learn-1.4.0-1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading imbalanced_learn-0.11.0-py3-none-any.whl (235 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.6/235.6 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: scikit-learn, imbalanced-learn\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed imbalanced-learn-0.11.0 scikit-learn-1.4.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall scikit-learn imbalanced-learn -y\n",
    "\n",
    "# Then install compatible versions\n",
    "!pip install scikit-learn==1.4.0 imbalanced-learn==0.11.0\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFECV, RFE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import  RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, SVMSMOTE, ADASYN,RandomOverSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0043690",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T08:58:25.769039Z",
     "iopub.status.busy": "2025-08-26T08:58:25.768198Z",
     "iopub.status.idle": "2025-08-26T08:58:25.773597Z",
     "shell.execute_reply": "2025-08-26T08:58:25.772832Z"
    },
    "papermill": {
     "duration": 0.012,
     "end_time": "2025-08-26T08:58:25.775360",
     "exception": false,
     "start_time": "2025-08-26T08:58:25.763360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b1a9e29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T08:58:25.783930Z",
     "iopub.status.busy": "2025-08-26T08:58:25.783524Z",
     "iopub.status.idle": "2025-08-26T08:58:25.837365Z",
     "shell.execute_reply": "2025-08-26T08:58:25.836197Z"
    },
    "papermill": {
     "duration": 0.060162,
     "end_time": "2025-08-26T08:58:25.839147",
     "exception": false,
     "start_time": "2025-08-26T08:58:25.778985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Sleep Duration</th>\n",
       "      <th>Quality of Sleep</th>\n",
       "      <th>Physical Activity Level</th>\n",
       "      <th>Stress Level</th>\n",
       "      <th>BMI Category</th>\n",
       "      <th>Blood Pressure</th>\n",
       "      <th>Heart Rate</th>\n",
       "      <th>Daily Steps</th>\n",
       "      <th>Sleep Disorder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>6.1</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>Overweight</td>\n",
       "      <td>126/83</td>\n",
       "      <td>77</td>\n",
       "      <td>4200</td>\n",
       "      <td>okay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>28</td>\n",
       "      <td>Doctor</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>8</td>\n",
       "      <td>Normal</td>\n",
       "      <td>125/80</td>\n",
       "      <td>75</td>\n",
       "      <td>10000</td>\n",
       "      <td>okay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>28</td>\n",
       "      <td>Doctor</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>8</td>\n",
       "      <td>Normal</td>\n",
       "      <td>125/80</td>\n",
       "      <td>75</td>\n",
       "      <td>10000</td>\n",
       "      <td>okay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>28</td>\n",
       "      <td>Sales Representative</td>\n",
       "      <td>5.9</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>Obese</td>\n",
       "      <td>140/90</td>\n",
       "      <td>85</td>\n",
       "      <td>3000</td>\n",
       "      <td>Sleep Apnea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Male</td>\n",
       "      <td>28</td>\n",
       "      <td>Sales Representative</td>\n",
       "      <td>5.9</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>Obese</td>\n",
       "      <td>140/90</td>\n",
       "      <td>85</td>\n",
       "      <td>3000</td>\n",
       "      <td>Sleep Apnea</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Person ID Gender  Age            Occupation  Sleep Duration  \\\n",
       "0          1   Male   27     Software Engineer             6.1   \n",
       "1          2   Male   28                Doctor             6.2   \n",
       "2          3   Male   28                Doctor             6.2   \n",
       "3          4   Male   28  Sales Representative             5.9   \n",
       "4          5   Male   28  Sales Representative             5.9   \n",
       "\n",
       "   Quality of Sleep  Physical Activity Level  Stress Level BMI Category  \\\n",
       "0                 6                       42             6   Overweight   \n",
       "1                 6                       60             8       Normal   \n",
       "2                 6                       60             8       Normal   \n",
       "3                 4                       30             8        Obese   \n",
       "4                 4                       30             8        Obese   \n",
       "\n",
       "  Blood Pressure  Heart Rate  Daily Steps Sleep Disorder  \n",
       "0         126/83          77         4200           okay  \n",
       "1         125/80          75        10000           okay  \n",
       "2         125/80          75        10000           okay  \n",
       "3         140/90          85         3000    Sleep Apnea  \n",
       "4         140/90          85         3000    Sleep Apnea  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"/kaggle/input/sleep-health-and-lifestyle-dataset/Sleep_health_and_lifestyle_dataset.csv\")\n",
    "\n",
    "df['Sleep Disorder'] = df['Sleep Disorder'].fillna(\"okay\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97241abe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T08:58:25.848736Z",
     "iopub.status.busy": "2025-08-26T08:58:25.848342Z",
     "iopub.status.idle": "2025-08-26T08:58:25.896156Z",
     "shell.execute_reply": "2025-08-26T08:58:25.895020Z"
    },
    "papermill": {
     "duration": 0.055117,
     "end_time": "2025-08-26T08:58:25.898328",
     "exception": false,
     "start_time": "2025-08-26T08:58:25.843211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"/kaggle/input/sleep-health-and-lifestyle-dataset/Sleep_health_and_lifestyle_dataset.csv\")\n",
    "\n",
    "df['Sleep Disorder'] = df['Sleep Disorder'].fillna(\"okay\")\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df=df.drop(['Person ID'],axis=1)\n",
    "# One-hot encode specific columns\n",
    "df = pd.get_dummies(df, columns=['Gender', 'Occupation', 'BMI Category','Blood Pressure'], drop_first=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['Sleep Disorder'] = le.fit_transform(df['Sleep Disorder'])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "target_col='Sleep Disorder'\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cebcc97b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T08:58:25.907726Z",
     "iopub.status.busy": "2025-08-26T08:58:25.907329Z",
     "iopub.status.idle": "2025-08-26T08:58:25.912973Z",
     "shell.execute_reply": "2025-08-26T08:58:25.912014Z"
    },
    "papermill": {
     "duration": 0.012095,
     "end_time": "2025-08-26T08:58:25.914576",
     "exception": false,
     "start_time": "2025-08-26T08:58:25.902481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280, 49) (94, 49)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b281baa4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T08:58:25.924379Z",
     "iopub.status.busy": "2025-08-26T08:58:25.923713Z",
     "iopub.status.idle": "2025-08-26T08:58:30.064956Z",
     "shell.execute_reply": "2025-08-26T08:58:30.063922Z"
    },
    "papermill": {
     "duration": 4.14839,
     "end_time": "2025-08-26T08:58:30.066799",
     "exception": false,
     "start_time": "2025-08-26T08:58:25.918409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Normalized + RandomOverSampler ===\n",
      "Original X_train: (280, 49) y_train: (280,)\n",
      "After SMOTE  X_res  : (492, 49) y_res  : (492,)\n",
      "Original class distribution: {1: 58, 2: 164, 0: 58}\n",
      "After SMOTE class distribution: {1: 164, 2: 164, 0: 164}\n",
      "\n",
      "=== Normalized + SMOTE ===\n",
      "Original X_train: (280, 49) y_train: (280,)\n",
      "After SMOTE  X_res  : (492, 49) y_res  : (492,)\n",
      "Original class distribution: {1: 58, 2: 164, 0: 58}\n",
      "After SMOTE class distribution: {1: 164, 2: 164, 0: 164}\n",
      "\n",
      "=== Normalized + Borderline-SMOTE ===\n",
      "Original X_train: (280, 49) y_train: (280,)\n",
      "After SMOTE  X_res  : (492, 49) y_res  : (492,)\n",
      "Original class distribution: {1: 58, 2: 164, 0: 58}\n",
      "After SMOTE class distribution: {1: 164, 2: 164, 0: 164}\n",
      "\n",
      "=== Normalized + SVMSMOTE ===\n",
      "Original X_train: (280, 49) y_train: (280,)\n",
      "After SMOTE  X_res  : (492, 49) y_res  : (492,)\n",
      "Original class distribution: {1: 58, 2: 164, 0: 58}\n",
      "After SMOTE class distribution: {1: 164, 2: 164, 0: 164}\n",
      "\n",
      "=== Normalized + ADASYN ===\n",
      "Original X_train: (280, 49) y_train: (280,)\n",
      "After SMOTE  X_res  : (475, 49) y_res  : (475,)\n",
      "Original class distribution: {1: 58, 2: 164, 0: 58}\n",
      "After SMOTE class distribution: {1: 154, 2: 164, 0: 157}\n",
      "\n",
      "=== Normalized + RandomUnderSampler ===\n",
      "Original X_train: (280, 49) y_train: (280,)\n",
      "After SMOTE  X_res  : (174, 49) y_res  : (174,)\n",
      "Original class distribution: {1: 58, 2: 164, 0: 58}\n",
      "After SMOTE class distribution: {0: 58, 1: 58, 2: 58}\n",
      "\n",
      "=== Normalized + ClusterCentroids ===\n",
      "Original X_train: (280, 49) y_train: (280,)\n",
      "After SMOTE  X_res  : (174, 49) y_res  : (174,)\n",
      "Original class distribution: {1: 58, 2: 164, 0: 58}\n",
      "After SMOTE class distribution: {0: 58, 1: 58, 2: 58}\n",
      "\n",
      "=== Normalized + TomekLinks ===\n",
      "Original X_train: (280, 49) y_train: (280,)\n",
      "After SMOTE  X_res  : (277, 49) y_res  : (277,)\n",
      "Original class distribution: {1: 58, 2: 164, 0: 58}\n",
      "After SMOTE class distribution: {1: 56, 2: 163, 0: 58}\n",
      "\n",
      "=== Normalized + NearMiss (v1) ===\n",
      "Original X_train: (280, 49) y_train: (280,)\n",
      "After SMOTE  X_res  : (174, 49) y_res  : (174,)\n",
      "Original class distribution: {1: 58, 2: 164, 0: 58}\n",
      "After SMOTE class distribution: {0: 58, 1: 58, 2: 58}\n",
      "\n",
      "=== Normalized + NearMiss (v2) ===\n",
      "Original X_train: (280, 49) y_train: (280,)\n",
      "After SMOTE  X_res  : (174, 49) y_res  : (174,)\n",
      "Original class distribution: {1: 58, 2: 164, 0: 58}\n",
      "After SMOTE class distribution: {0: 58, 1: 58, 2: 58}\n",
      "\n",
      "=== Normalized + NearMiss (v3) ===\n",
      "Original X_train: (280, 49) y_train: (280,)\n",
      "After SMOTE  X_res  : (158, 49) y_res  : (158,)\n",
      "Original class distribution: {1: 58, 2: 164, 0: 58}\n",
      "After SMOTE class distribution: {0: 58, 1: 55, 2: 45}\n",
      "\n",
      "=== Normalized + SMOTE + TomekLinks ===\n",
      "Original X_train: (280, 49) y_train: (280,)\n",
      "After SMOTE  X_res  : (491, 49) y_res  : (491,)\n",
      "Original class distribution: {1: 58, 2: 164, 0: 58}\n",
      "After SMOTE class distribution: {1: 163, 2: 164, 0: 164}\n",
      "\n",
      "=== Normalized + SMOTE + ENN ===\n",
      "Original X_train: (280, 49) y_train: (280,)\n",
      "After SMOTE  X_res  : (354, 49) y_res  : (354,)\n",
      "Original class distribution: {1: 58, 2: 164, 0: 58}\n",
      "After SMOTE class distribution: {0: 112, 1: 118, 2: 124}\n",
      "\n",
      "=== SVM Model Performance with Hyperparameter Tuning ===\n",
      "\n",
      "Running SVM with Original Data configuration...\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.585714  0.246246 0.333333   0.195238      0.5\n",
      "    Test  0.585106  0.246085 0.333333   0.195035      0.5\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 100, 'coef0': 0.0, 'degree': 2, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "\n",
      "Running SVM with Normalized Data configuration...\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.932143  0.918933 0.909378   0.930465 0.952281\n",
      "    Test  0.914894  0.894070 0.907337   0.882984 0.952818\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 100, 'coef0': 0.0, 'degree': 2, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "\n",
      "Running SVM with Normalized + RandomOverSampler configuration...\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.918699  0.918875 0.918699   0.924507 0.969060\n",
      "    Test  0.914894  0.894070 0.907337   0.882984 0.941839\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 100, 'coef0': 0.0, 'degree': 2, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "\n",
      "Running SVM with Normalized + SMOTE configuration...\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.924797  0.925474 0.924797   0.930437 0.975560\n",
      "    Test  0.904255  0.877513 0.890670   0.866606 0.930522\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 100, 'coef0': 0.0, 'degree': 2, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "\n",
      "Running SVM with Normalized + Borderline-SMOTE configuration...\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.833333  0.833956 0.833333   0.840283 0.951752\n",
      "    Test  0.861702  0.843289 0.877033   0.823222 0.911691\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 100, 'coef0': 0.0, 'degree': 2, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "\n",
      "Running SVM with Normalized + SVMSMOTE configuration...\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.880081  0.880713 0.880081   0.883827 0.966996\n",
      "    Test  0.861702  0.838206 0.866427   0.822897 0.931304\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 100, 'coef0': 0.0, 'degree': 2, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "\n",
      "Running SVM with Normalized + ADASYN configuration...\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.854737  0.855615 0.853829   0.862389 0.962670\n",
      "    Test  0.872340  0.853487 0.883094   0.835227 0.915721\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 100, 'coef0': 0.0, 'degree': 2, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "\n",
      "Running SVM with Normalized + RandomUnderSampler configuration...\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.908046  0.908302 0.908046   0.914345 0.950555\n",
      "    Test  0.904255  0.884133 0.901276   0.871000 0.948551\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 100, 'coef0': 0.0, 'degree': 2, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "\n",
      "Running SVM with Normalized + ClusterCentroids configuration...\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.890805  0.891185 0.890805   0.894742 0.942826\n",
      "    Test  0.914894  0.894070 0.907337   0.882984 0.951089\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 100, 'coef0': 0.0, 'degree': 2, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "\n",
      "Running SVM with Normalized + TomekLinks configuration...\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.931408  0.917810 0.908289   0.929311 0.952651\n",
      "    Test  0.904255  0.876976 0.891547   0.868494 0.961790\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 100, 'coef0': 0.0, 'degree': 2, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "\n",
      "Running SVM with Normalized + NearMiss (v1) configuration...\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.919540  0.919940 0.919540   0.922647 0.957689\n",
      "    Test  0.574468  0.597427 0.724003   0.677579 0.829653\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 100, 'coef0': 0.0, 'degree': 2, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "\n",
      "Running SVM with Normalized + NearMiss (v2) configuration...\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.936782  0.936675 0.936782   0.938276 0.971264\n",
      "    Test  0.680851  0.698958 0.774003   0.729870 0.850634\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 100, 'coef0': 0.0, 'degree': 2, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "\n",
      "Running SVM with Normalized + NearMiss (v3) configuration...\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.892405  0.890290 0.892430   0.889954 0.942596\n",
      "    Test  0.712766  0.723015 0.792185   0.747727 0.904751\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 100, 'coef0': 0.0, 'degree': 2, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "\n",
      "Running SVM with Normalized + SMOTE + TomekLinks configuration...\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.926680  0.927323 0.926655   0.931960 0.974979\n",
      "    Test  0.904255  0.877513 0.890670   0.866606 0.930064\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 100, 'coef0': 0.0, 'degree': 2, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "\n",
      "Running SVM with Normalized + SMOTE + ENN configuration...\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.997175  0.997243 0.997175   0.997333 1.000000\n",
      "    Test  0.851064  0.815629 0.838278   0.800839 0.910014\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 100, 'coef0': 0.0, 'degree': 2, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "\n",
      "=== Final Summary of All Results ===\n",
      "                    Model                   Configuration  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Support Vector Machine 99                   Original Data  0.585106  0.246085 0.333333   0.195035 0.500000\n",
      "Support Vector Machine 99                 Normalized Data  0.914894  0.894070 0.907337   0.882984 0.952818\n",
      "Support Vector Machine 99  Normalized + RandomOverSampler  0.914894  0.894070 0.907337   0.882984 0.941839\n",
      "Support Vector Machine 99              Normalized + SMOTE  0.904255  0.877513 0.890670   0.866606 0.930522\n",
      "Support Vector Machine 99   Normalized + Borderline-SMOTE  0.861702  0.843289 0.877033   0.823222 0.911691\n",
      "Support Vector Machine 99           Normalized + SVMSMOTE  0.861702  0.838206 0.866427   0.822897 0.931304\n",
      "Support Vector Machine 99             Normalized + ADASYN  0.872340  0.853487 0.883094   0.835227 0.915721\n",
      "Support Vector Machine 99 Normalized + RandomUnderSampler  0.904255  0.884133 0.901276   0.871000 0.948551\n",
      "Support Vector Machine 99   Normalized + ClusterCentroids  0.914894  0.894070 0.907337   0.882984 0.951089\n",
      "Support Vector Machine 99         Normalized + TomekLinks  0.904255  0.876976 0.891547   0.868494 0.961790\n",
      "Support Vector Machine 99      Normalized + NearMiss (v1)  0.574468  0.597427 0.724003   0.677579 0.829653\n",
      "Support Vector Machine 99      Normalized + NearMiss (v2)  0.680851  0.698958 0.774003   0.729870 0.850634\n",
      "Support Vector Machine 99      Normalized + NearMiss (v3)  0.712766  0.723015 0.792185   0.747727 0.904751\n",
      "Support Vector Machine 99 Normalized + SMOTE + TomekLinks  0.904255  0.877513 0.890670   0.866606 0.930064\n",
      "Support Vector Machine 99        Normalized + SMOTE + ENN  0.851064  0.815629 0.838278   0.800839 0.910014\n"
     ]
    }
   ],
   "source": [
    "ML_Model = []\n",
    "ML_Config = []\n",
    "accuracy = []\n",
    "f1_score = []\n",
    "recall = []\n",
    "precision = []\n",
    "auc_roc = []  # Adding a holder for AUC-ROC\n",
    "\n",
    "\n",
    "def storeResults(model, config, a, b, c, d, e):\n",
    "    \"\"\"\n",
    "    Store model performance results\n",
    "    \n",
    "    Parameters:\n",
    "    model: Name of the ML model\n",
    "    config: Configuration name (preprocessing steps applied)\n",
    "    a: Accuracy score\n",
    "    b: F1 score\n",
    "    c: Recall score\n",
    "    d: Precision score\n",
    "    e: AUC-ROC score\n",
    "    \"\"\"\n",
    "    ML_Model.append(model)\n",
    "    ML_Config.append(config)\n",
    "    accuracy.append(round(a, 6))\n",
    "    f1_score.append(round(b, 6))\n",
    "    recall.append(round(c, 6))\n",
    "    precision.append(round(d, 6))\n",
    "    auc_roc.append(round(e, 6))\n",
    "\n",
    "\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 1: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# === Step 1.5 (NEW): Oversampling variants on the normalized training set ===\n",
    "# We oversample ONLY the training fold; test fold stays untouched for fair evaluation.\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, BorderlineSMOTE, SVMSMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler, ClusterCentroids, NearMiss\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, BorderlineSMOTE, SVMSMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler, ClusterCentroids, NearMiss, TomekLinks\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "\n",
    "samplers = [\n",
    "    # Over-sampling techniques\n",
    "    ('Normalized + RandomOverSampler', RandomOverSampler(\n",
    "        sampling_strategy='auto',\n",
    "        random_state=42\n",
    "    )),\n",
    "    ('Normalized + SMOTE', SMOTE(\n",
    "        sampling_strategy='auto',\n",
    "        k_neighbors=5,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )),\n",
    "    ('Normalized + Borderline-SMOTE', BorderlineSMOTE(\n",
    "        kind='borderline-1',\n",
    "        k_neighbors=5,\n",
    "        m_neighbors=20,\n",
    "        sampling_strategy='auto',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )),\n",
    "    ('Normalized + SVMSMOTE', SVMSMOTE(\n",
    "        k_neighbors=5,\n",
    "        m_neighbors=20,\n",
    "        sampling_strategy='auto',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )),\n",
    "    ('Normalized + ADASYN', ADASYN(\n",
    "        sampling_strategy='auto',\n",
    "        n_neighbors=5,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )),\n",
    "\n",
    "    # Under-sampling techniques with more parameters\n",
    "    ('Normalized + RandomUnderSampler', RandomUnderSampler(\n",
    "        sampling_strategy='auto',\n",
    "        replacement=False,\n",
    "        random_state=42\n",
    "    )),\n",
    "    ('Normalized + ClusterCentroids', ClusterCentroids(\n",
    "        sampling_strategy='auto',\n",
    "        estimator=None,     # Defaults to KMeans\n",
    "        voting='auto',\n",
    "        random_state=42\n",
    "    )),\n",
    "    ('Normalized + TomekLinks', TomekLinks(\n",
    "        sampling_strategy='auto'\n",
    "       \n",
    "    )),\n",
    "    ('Normalized + NearMiss (v1)', NearMiss(\n",
    "        sampling_strategy='auto',\n",
    "        version=1,\n",
    "        n_neighbors=5\n",
    "      \n",
    "    )),\n",
    "    ('Normalized + NearMiss (v2)', NearMiss(\n",
    "        sampling_strategy='auto',\n",
    "        version=2,\n",
    "        n_neighbors=5\n",
    "    )),\n",
    "    ('Normalized + NearMiss (v3)', NearMiss(\n",
    "        sampling_strategy='auto',\n",
    "        version=3,\n",
    "        n_neighbors_ver3=5\n",
    "        \n",
    "    )),\n",
    "\n",
    "    # Hybrid methods\n",
    "    ('Normalized + SMOTE + TomekLinks', SMOTETomek(\n",
    "        sampling_strategy='auto',\n",
    "        smote=SMOTE(\n",
    "            sampling_strategy='auto',\n",
    "            k_neighbors=5,\n",
    "            random_state=42\n",
    "        ),\n",
    "        tomek=TomekLinks(\n",
    "            sampling_strategy='auto'\n",
    "        \n",
    "        ),\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )),\n",
    "    ('Normalized + SMOTE + ENN', SMOTEENN(\n",
    "        sampling_strategy='auto',\n",
    "        smote=SMOTE(\n",
    "            sampling_strategy='auto',\n",
    "            k_neighbors=5,\n",
    "            random_state=42\n",
    "            \n",
    "        ),\n",
    "        enn=None,  # Use default ENN\n",
    "        random_state=42\n",
    "        \n",
    "    )),\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for cfg_name, sampler in samplers:\n",
    "    X_res, y_res = sampler.fit_resample(X_train_normalized, y_train)\n",
    "    configurations.append((cfg_name, X_res, X_test_normalized, y_res))\n",
    "    print(f\"\\n=== {cfg_name} ===\")\n",
    "    print(\"Original X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
    "    print(\"After SMOTE  X_res  :\", X_res.shape, \"y_res  :\", y_res.shape)\n",
    "    print(\"Original class distribution:\", dict(Counter(y_train)))\n",
    "    print(\"After SMOTE class distribution:\", dict(Counter(y_res)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Step 2: SVM + GridSearchCV\n",
    "print(\"\\n=== SVM Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'C': [100],\n",
    "    'gamma': ['auto'],\n",
    "    'kernel': ['sigmoid'],\n",
    "    'degree': [2],\n",
    "    'coef0': [0.0]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning SVM with {name} configuration...\")\n",
    "    svc = GridSearchCV(SVC(probability=True), param_grid, cv=2, n_jobs=-1, verbose=2)\n",
    "    svc.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_svc = svc.predict(X_train_cfg)\n",
    "    y_test_svc = svc.predict(X_test_cfg)\n",
    "    y_train_svc_proba = svc.predict_proba(X_train_cfg)\n",
    "    y_test_svc_proba = svc.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_svc),\n",
    "            metrics.accuracy_score(y_test, y_test_svc),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_svc, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_svc, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_svc, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_svc, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_svc, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_svc, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_svc_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_svc_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nSupport Vector Machine Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_svc_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'Support Vector Machine 99',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_svc),\n",
    "        metrics.f1_score(y_test, y_test_svc, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_svc, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_svc, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(svc.best_params_)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    \"Model\": ML_Model,\n",
    "    \"Configuration\": ML_Config,\n",
    "    \"Accuracy\": accuracy,\n",
    "    \"F1 Score\": f1_score,\n",
    "    \"Recall\": recall,\n",
    "    \"Precision\": precision,\n",
    "    \"AUC-ROC\": auc_roc\n",
    "})\n",
    "\n",
    "print(\"\\n=== Final Summary of All Results ===\")\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fabbd3",
   "metadata": {
    "papermill": {
     "duration": 0.003793,
     "end_time": "2025-08-26T08:58:30.075080",
     "exception": false,
     "start_time": "2025-08-26T08:58:30.071287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3321433,
     "sourceId": 6491929,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 35.647209,
   "end_time": "2025-08-26T08:58:32.699803",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-26T08:57:57.052594",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
