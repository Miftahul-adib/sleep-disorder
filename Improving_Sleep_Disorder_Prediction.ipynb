{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8mfejZl6MQjmrx3vkKq+T"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Importing Libraries\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Yb1fHaSMPI85"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "diEVyiMoJ4Cm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from imblearn.over_sampling import ADASYN, SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import CondensedNearestNeighbour, TomekLinks, RandomUnderSampler\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Load & Preprocessing"
      ],
      "metadata": {
        "id": "unb2qil8SoTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/Sleep_health_and_lifestyle_dataset.csv\")\n",
        "df.fillna(\"None\", inplace=True)\n",
        "df[['Systolic BP', 'Diastolic BP']] = df['Blood Pressure'].str.split('/', expand=True)\n",
        "df.drop(['Person ID', 'Blood Pressure'], axis=1, inplace=True)\n",
        "df = pd.get_dummies(df, columns=['Occupation', 'BMI Category'], drop_first=False)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "columns_to_encode = ['Gender', 'Sleep Disorder']\n",
        "for col in columns_to_encode:\n",
        "    df[col] = label_encoder.fit_transform(df[col])\n",
        "\n",
        "X = df.drop('Sleep Disorder', axis=1)\n",
        "y = df['Sleep Disorder']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "R6yAAGUeSsn3"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ML Model Result Storage"
      ],
      "metadata": {
        "id": "TpEDoK5Ihy4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ML_Model = []\n",
        "ML_Config = []\n",
        "accuracy = []\n",
        "f1_score = []\n",
        "recall = []\n",
        "precision = []\n",
        "auc_roc = []  # Adding a holder for AUC-ROC\n",
        "\n",
        "# Function to call for storing the results\n",
        "def storeResults(model, config, a, b, c, d, e):\n",
        "    \"\"\"\n",
        "    Store model performance results\n",
        "\n",
        "    Parameters:\n",
        "    model: Name of the ML model\n",
        "    config: Configuration name (preprocessing steps applied)\n",
        "    a: Accuracy score\n",
        "    b: F1 score\n",
        "    c: Recall score\n",
        "    d: Precision score\n",
        "    e: AUC-ROC score\n",
        "    \"\"\"\n",
        "    ML_Model.append(model)\n",
        "    ML_Config.append(config)\n",
        "    accuracy.append(round(a, 6))\n",
        "    f1_score.append(round(b, 6))\n",
        "    recall.append(round(c, 6))\n",
        "    precision.append(round(d, 6))\n",
        "    auc_roc.append(round(e, 6))"
      ],
      "metadata": {
        "id": "tlV5BgjKhyYX"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest with K-Fold, Oversampling, Undersampling, Randomsampling"
      ],
      "metadata": {
        "id": "SHcHbkJxdLvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "configurations = []\n",
        "configurations.append(('Original Data', X_train, X_test, y_train))\n",
        "\n",
        "# Step 2: Normalize the data\n",
        "scaler = MinMaxScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "X_train_normalized = scaler.transform(X_train)\n",
        "X_test_normalized = scaler.transform(X_test)\n",
        "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
        "\n",
        "# applying k-fold cv with Random Forest\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# RandomForest classifier\n",
        "rfc = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "cv_score = cross_val_score(rfc, X_normalized, y, cv=kfold, scoring='accuracy').mean()\n",
        "cv_score = float(cv_score)\n",
        "print(\"\\nApplying K-Fold cross validation Random Forest's score is: \", cv_score)\n",
        "\n",
        "# applying oversampling Smote & ADASYN\n",
        "smote = SMOTE(random_state=42)\n",
        "adasyn = ADASYN(random_state=42)\n",
        "X_train_resample_smote, y_train_resample_smote = smote.fit_resample(X_train_normalized, y_train)\n",
        "X_train_resample_adasyn, y_train_resample_adasyn = adasyn.fit_resample(X_train_normalized, y_train)\n",
        "configurations.append(('SMOTE', X_train_resample_smote, X_test_normalized, y_train_resample_smote))\n",
        "configurations.append(('ADASYN', X_train_resample_adasyn, X_test_normalized, y_train_resample_adasyn))\n",
        "\n",
        "# applying undersampling CNN & Tomek Links\n",
        "cnn = CondensedNearestNeighbour(random_state=42)\n",
        "tomek = TomekLinks()\n",
        "X_train_resample_cnn, y_train_resample_cnn = cnn.fit_resample(X_train_normalized, y_train)\n",
        "X_train_resample_tomek, y_train_resample_tomek = tomek.fit_resample(X_train_normalized, y_train)\n",
        "configurations.append(('CondensedNN', X_train_resample_cnn, X_test_normalized, y_train_resample_cnn))\n",
        "configurations.append(('Tomek Links', X_train_resample_tomek, X_test_normalized, y_train_resample_tomek))\n",
        "\n",
        "# applying randomsampling Randomoversampling & Randomundersampling\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "X_train_resample_ros, y_train_resample_ros = ros.fit_resample(X_train_normalized, y_train)\n",
        "X_train_resample_rus, y_train_resample_rus = rus.fit_resample(X_train_normalized, y_train)\n",
        "configurations.append(('Random Oversampling', X_train_resample_ros, X_test_normalized, y_train_resample_ros))\n",
        "configurations.append(('Random Undersampling', X_train_resample_rus, X_test_normalized, y_train_resample_rus))\n",
        "\n",
        "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
        "  rfc.fit(X_train_cfg, y_train_cfg)\n",
        "\n",
        "  y_train_rf = rfc.predict(X_train_cfg)\n",
        "  y_test_rf = rfc.predict(X_test_cfg)\n",
        "  y_train_rf_proba = rfc.predict_proba(X_train_cfg)\n",
        "  y_test_rf_proba = rfc.predict_proba(X_test_cfg)\n",
        "\n",
        "  metrics_dict = {\n",
        "        \"Dataset\": [\"Training\", \"Test\"],\n",
        "        \"Accuracy\": [\n",
        "            metrics.accuracy_score(y_train_cfg, y_train_rf),\n",
        "            metrics.accuracy_score(y_test, y_test_rf),\n",
        "        ],\n",
        "        \"F1 Score\": [\n",
        "            metrics.f1_score(y_train_cfg, y_train_rf, average='macro'),\n",
        "            metrics.f1_score(y_test, y_test_rf, average='macro'),\n",
        "        ],\n",
        "        \"Recall\": [\n",
        "            metrics.recall_score(y_train_cfg, y_train_rf, average='macro'),\n",
        "            metrics.recall_score(y_test, y_test_rf, average='macro'),\n",
        "        ],\n",
        "        \"Precision\": [\n",
        "            metrics.precision_score(y_train_cfg, y_train_rf, average='macro'),\n",
        "            metrics.precision_score(y_test, y_test_rf, average='macro'),\n",
        "        ],\n",
        "        \"AUC-ROC\": [\n",
        "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_rf_proba, multi_class='ovr', average='macro'),\n",
        "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_rf_proba, multi_class='ovr', average='macro'),\n",
        "        ]\n",
        "    }\n",
        "\n",
        "  df_metrics = pd.DataFrame(metrics_dict)\n",
        "  print(\"\\nRandom Forest Model Performance Metrics\")\n",
        "  print(\"Configuration Name: \", name)\n",
        "  print(df_metrics.to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7NTek4OUXv5",
        "outputId": "6f1c62dd-15ce-4f79-e8f5-6eb394f56309"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Applying K-Fold cross validation Random Forest's score is:  0.9066856330014224\n",
            "\n",
            "Random Forest Model Performance Metrics\n",
            "Configuration Name:  Original Data\n",
            " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
            "Training  0.932143  0.923843 0.921041   0.927580 0.990345\n",
            "    Test  0.893617  0.843243 0.844207   0.851058 0.928146\n",
            "\n",
            "Random Forest Model Performance Metrics\n",
            "Configuration Name:  Normalized Data\n",
            " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
            "Training  0.932143  0.923843 0.921041   0.927580 0.990282\n",
            "    Test  0.893617  0.843243 0.844207   0.851058 0.927725\n",
            "\n",
            "Random Forest Model Performance Metrics\n",
            "Configuration Name:  SMOTE\n",
            " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
            "Training  0.961382  0.961429 0.961382   0.961621 0.995024\n",
            "    Test  0.914894  0.876705 0.874510   0.880688 0.919585\n",
            "\n",
            "Random Forest Model Performance Metrics\n",
            "Configuration Name:  ADASYN\n",
            " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
            "Training  0.960159  0.960070 0.960115   0.960127 0.994535\n",
            "    Test  0.893617  0.843243 0.844207   0.851058 0.903342\n",
            "\n",
            "Random Forest Model Performance Metrics\n",
            "Configuration Name:  CondensedNN\n",
            " Dataset  Accuracy  F1 Score  Recall  Precision  AUC-ROC\n",
            "Training  0.890000  0.875327 0.85119   0.911937 0.974570\n",
            "    Test  0.861702  0.801201 0.79893   0.811772 0.886398\n",
            "\n",
            "Random Forest Model Performance Metrics\n",
            "Configuration Name:  Tomek Links\n",
            " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
            "Training  0.931900  0.923339 0.920382   0.927255 0.990031\n",
            "    Test  0.893617  0.843243 0.844207   0.851058 0.925311\n",
            "\n",
            "Random Forest Model Performance Metrics\n",
            "Configuration Name:  Random Oversampling\n",
            " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
            "Training  0.934959  0.934635 0.934959   0.934878 0.992775\n",
            "    Test  0.808511  0.768019 0.795722   0.760079 0.914976\n",
            "\n",
            "Random Forest Model Performance Metrics\n",
            "Configuration Name:  Random Undersampling\n",
            " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
            "Training  0.934524  0.935039 0.934524   0.937719 0.994951\n",
            "    Test  0.861702  0.812066 0.826025   0.817664 0.915153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree with K-Fold, Oversampling, Undersampling, Randomsampling"
      ],
      "metadata": {
        "id": "X_F-w3vDsLHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "configurations = []\n",
        "configurations.append(('Original Data', X_train, X_test, y_train))\n",
        "\n",
        "# Step 2: Normalize the data\n",
        "scaler = MinMaxScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "X_train_normalized = scaler.transform(X_train)\n",
        "X_test_normalized = scaler.transform(X_test)\n",
        "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
        "\n",
        "# applying k-fold cv with Decision Tree\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# DecisionTree classifier\n",
        "dtc = DecisionTreeClassifier(random_state=42)\n",
        "cv_score = cross_val_score(dtc, X_normalized, y, cv=kfold, scoring='accuracy').mean()\n",
        "cv_score = float(cv_score)\n",
        "print(\"\\nApplying K-Fold cross validation Decision Tree's score is: \", cv_score)\n",
        "\n",
        "# applying oversampling Smote & ADASYN\n",
        "smote = SMOTE(random_state=42)\n",
        "adasyn = ADASYN(random_state=42)\n",
        "X_train_resample_smote, y_train_resample_smote = smote.fit_resample(X_train_normalized, y_train)\n",
        "X_train_resample_adasyn, y_train_resample_adasyn = adasyn.fit_resample(X_train_normalized, y_train)\n",
        "configurations.append(('SMOTE', X_train_resample_smote, X_test_normalized, y_train_resample_smote))\n",
        "configurations.append(('ADASYN', X_train_resample_adasyn, X_test_normalized, y_train_resample_adasyn))\n",
        "\n",
        "# applying undersampling CNN & Tomek Links\n",
        "cnn = CondensedNearestNeighbour(random_state=42)\n",
        "tomek = TomekLinks()\n",
        "X_train_resample_cnn, y_train_resample_cnn = cnn.fit_resample(X_train_normalized, y_train)\n",
        "X_train_resample_tomek, y_train_resample_tomek = tomek.fit_resample(X_train_normalized, y_train)\n",
        "configurations.append(('CondensedNN', X_train_resample_cnn, X_test_normalized, y_train_resample_cnn))\n",
        "configurations.append(('Tomek Links', X_train_resample_tomek, X_test_normalized, y_train_resample_tomek))\n",
        "\n",
        "# applying randomsampling Randomoversampling & Randomundersampling\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "X_train_resample_ros, y_train_resample_ros = ros.fit_resample(X_train_normalized, y_train)\n",
        "X_train_resample_rus, y_train_resample_rus = rus.fit_resample(X_train_normalized, y_train)\n",
        "configurations.append(('Random Oversampling', X_train_resample_ros, X_test_normalized, y_train_resample_ros))\n",
        "configurations.append(('Random Undersampling', X_train_resample_rus, X_test_normalized, y_train_resample_rus))\n",
        "\n",
        "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
        "  dtc.fit(X_train_cfg, y_train_cfg)\n",
        "\n",
        "  y_train_dt = dtc.predict(X_train_cfg)\n",
        "  y_test_dt = dtc.predict(X_test_cfg)\n",
        "  y_train_dt_proba = dtc.predict_proba(X_train_cfg)\n",
        "  y_test_dt_proba = dtc.predict_proba(X_test_cfg)\n",
        "\n",
        "  metrics_dict = {\n",
        "        \"Dataset\": [\"Training\", \"Test\"],\n",
        "        \"Accuracy\": [\n",
        "            metrics.accuracy_score(y_train_cfg, y_train_dt),\n",
        "            metrics.accuracy_score(y_test, y_test_dt),\n",
        "        ],\n",
        "        \"F1 Score\": [\n",
        "            metrics.f1_score(y_train_cfg, y_train_dt, average='macro'),\n",
        "            metrics.f1_score(y_test, y_test_dt, average='macro'),\n",
        "        ],\n",
        "        \"Recall\": [\n",
        "            metrics.recall_score(y_train_cfg, y_train_dt, average='macro'),\n",
        "            metrics.recall_score(y_test, y_test_dt, average='macro'),\n",
        "        ],\n",
        "        \"Precision\": [\n",
        "            metrics.precision_score(y_train_cfg, y_train_dt, average='macro'),\n",
        "            metrics.precision_score(y_test, y_test_dt, average='macro'),\n",
        "        ],\n",
        "        \"AUC-ROC\": [\n",
        "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_dt_proba, multi_class='ovr', average='macro'),\n",
        "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_dt_proba, multi_class='ovr', average='macro'),\n",
        "        ]\n",
        "    }\n",
        "\n",
        "  df_metrics = pd.DataFrame(metrics_dict)\n",
        "  print(\"\\nDeicion Tree Model Performance Metrics\")\n",
        "  print(\"Configuration Name: \", name)\n",
        "  print(df_metrics.to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gFupPmNsedu",
        "outputId": "4ddbe4e8-dd9a-4fc6-900a-a7a964012aba"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Applying K-Fold cross validation Decision Tree's score is:  0.8907539118065433\n",
            "\n",
            "Deicion Tree Model Performance Metrics\n",
            "Configuration Name:  Original Data\n",
            " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
            "Training  0.932143  0.923808 0.920645   0.927169 0.990717\n",
            "    Test  0.893617  0.843243 0.844207   0.851058 0.887355\n",
            "\n",
            "Deicion Tree Model Performance Metrics\n",
            "Configuration Name:  Normalized Data\n",
            " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
            "Training  0.932143  0.923808 0.920645   0.927169 0.990717\n",
            "    Test  0.893617  0.843243 0.844207   0.851058 0.887355\n",
            "\n",
            "Deicion Tree Model Performance Metrics\n",
            "Configuration Name:  SMOTE\n",
            " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
            "Training  0.961382  0.961431 0.961382   0.961527 0.996486\n",
            "    Test  0.914894  0.876705 0.874510   0.880688 0.908142\n",
            "\n",
            "Deicion Tree Model Performance Metrics\n",
            "Configuration Name:  ADASYN\n",
            " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
            "Training  0.960159  0.960070 0.960115   0.960127 0.996383\n",
            "    Test  0.904255  0.869866 0.863815   0.887228 0.895316\n",
            "\n",
            "Deicion Tree Model Performance Metrics\n",
            "Configuration Name:  CondensedNN\n",
            " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
            "Training  0.890000  0.882172 0.907738   0.864646 0.978374\n",
            "    Test  0.585106  0.608835 0.654902   0.696098 0.836968\n",
            "\n",
            "Deicion Tree Model Performance Metrics\n",
            "Configuration Name:  Tomek Links\n",
            " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
            "Training  0.931900  0.923321 0.920080   0.926766 0.990627\n",
            "    Test  0.893617  0.843243 0.844207   0.851058 0.887355\n",
            "\n",
            "Deicion Tree Model Performance Metrics\n",
            "Configuration Name:  Random Oversampling\n",
            " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
            "Training  0.934959  0.934700 0.934959   0.934872 0.992874\n",
            "    Test  0.829787  0.798104 0.826025   0.786616 0.908142\n",
            "\n",
            "Deicion Tree Model Performance Metrics\n",
            "Configuration Name:  Random Undersampling\n",
            " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
            "Training  0.934524  0.934894 0.934524   0.937269 0.995057\n",
            "    Test  0.797872  0.760091 0.789661   0.767708 0.872705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Boosting with K-Fold, Oversampling, Undersampling, Randomsampling"
      ],
      "metadata": {
        "id": "RQWUpTh_uU8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "configurations = []\n",
        "configurations.append(('Original Data', X_train, X_test, y_train))\n",
        "\n",
        "# Step 2: Normalize the data\n",
        "scaler = MinMaxScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "X_train_normalized = scaler.transform(X_train)\n",
        "X_test_normalized = scaler.transform(X_test)\n",
        "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
        "\n",
        "# applying k-fold cv with Gradient Boosting\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# GradientBoosting classifier\n",
        "gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=10, random_state=42)\n",
        "cv_score = cross_val_score(gbc, X_normalized, y, cv=kfold, scoring='accuracy').mean()\n",
        "cv_score = float(cv_score)\n",
        "print(\"\\nApplying K-Fold cross validation Gradient Boosting's score is: \", cv_score)\n",
        "\n",
        "# applying oversampling Smote & ADASYN\n",
        "smote = SMOTE(random_state=42)\n",
        "adasyn = ADASYN(random_state=42)\n",
        "X_train_resample_smote, y_train_resample_smote = smote.fit_resample(X_train_normalized, y_train)\n",
        "X_train_resample_adasyn, y_train_resample_adasyn = adasyn.fit_resample(X_train_normalized, y_train)\n",
        "configurations.append(('SMOTE', X_train_resample_smote, X_test_normalized, y_train_resample_smote))\n",
        "configurations.append(('ADASYN', X_train_resample_adasyn, X_test_normalized, y_train_resample_adasyn))\n",
        "\n",
        "# applying undersampling CNN & Tomek Links\n",
        "cnn = CondensedNearestNeighbour(random_state=42)\n",
        "tomek = TomekLinks()\n",
        "X_train_resample_cnn, y_train_resample_cnn = cnn.fit_resample(X_train_normalized, y_train)\n",
        "X_train_resample_tomek, y_train_resample_tomek = tomek.fit_resample(X_train_normalized, y_train)\n",
        "configurations.append(('CondensedNN', X_train_resample_cnn, X_test_normalized, y_train_resample_cnn))\n",
        "configurations.append(('Tomek Links', X_train_resample_tomek, X_test_normalized, y_train_resample_tomek))\n",
        "\n",
        "# applying randomsampling Randomoversampling & Randomundersampling\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "X_train_resample_ros, y_train_resample_ros = ros.fit_resample(X_train_normalized, y_train)\n",
        "X_train_resample_rus, y_train_resample_rus = rus.fit_resample(X_train_normalized, y_train)\n",
        "configurations.append(('Random Oversampling', X_train_resample_ros, X_test_normalized, y_train_resample_ros))\n",
        "configurations.append(('Random Undersampling', X_train_resample_rus, X_test_normalized, y_train_resample_rus))\n",
        "\n",
        "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
        "  gbc.fit(X_train_cfg, y_train_cfg)\n",
        "\n",
        "  y_train_gb = gbc.predict(X_train_cfg)\n",
        "  y_test_gb = gbc.predict(X_test_cfg)\n",
        "  y_train_gb_proba = gbc.predict_proba(X_train_cfg)\n",
        "  y_test_gb_proba = gbc.predict_proba(X_test_cfg)\n",
        "\n",
        "  metrics_dict = {\n",
        "        \"Dataset\": [\"Training\", \"Test\"],\n",
        "        \"Accuracy\": [\n",
        "            metrics.accuracy_score(y_train_cfg, y_train_gb),\n",
        "            metrics.accuracy_score(y_test, y_test_gb),\n",
        "        ],\n",
        "        \"F1 Score\": [\n",
        "            metrics.f1_score(y_train_cfg, y_train_gb, average='macro'),\n",
        "            metrics.f1_score(y_test, y_test_gb, average='macro'),\n",
        "        ],\n",
        "        \"Recall\": [\n",
        "            metrics.recall_score(y_train_cfg, y_train_gb, average='macro'),\n",
        "            metrics.recall_score(y_test, y_test_gb, average='macro'),\n",
        "        ],\n",
        "        \"Precision\": [\n",
        "            metrics.precision_score(y_train_cfg, y_train_gb, average='macro'),\n",
        "            metrics.precision_score(y_test, y_test_gb, average='macro'),\n",
        "        ],\n",
        "        \"AUC-ROC\": [\n",
        "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_gb_proba, multi_class='ovr', average='macro'),\n",
        "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_gb_proba, multi_class='ovr', average='macro'),\n",
        "        ]\n",
        "    }\n",
        "\n",
        "  df_metrics = pd.DataFrame(metrics_dict)\n",
        "  print(\"\\nGradien Boosting Model Performance Metrics\")\n",
        "  print(\"Configuration Name: \", name)\n",
        "  print(df_metrics.to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XoccNFtuYDy",
        "outputId": "db2ec8d5-8941-463f-feb9-c42ed0bfdf0a"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Applying K-Fold cross validation Gradient Boosting's score is:  0.9092460881934565\n",
            "\n",
            "Gradien Boosting Model Performance Metrics\n",
            "Configuration Name:  Original Data\n",
            " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
            "Training  0.932143  0.923808 0.920645   0.927169 0.990717\n",
            "    Test  0.893617  0.843243 0.844207   0.851058 0.890514\n",
            "\n",
            "Gradien Boosting Model Performance Metrics\n",
            "Configuration Name:  Normalized Data\n",
            " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
            "Training  0.932143  0.923808 0.920645   0.927169 0.990717\n",
            "    Test  0.893617  0.843243 0.844207   0.851058 0.890514\n",
            "\n",
            "Gradien Boosting Model Performance Metrics\n",
            "Configuration Name:  SMOTE\n",
            " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
            "Training  0.961382  0.961429 0.961382   0.961621 0.996486\n",
            "    Test  0.914894  0.876705 0.874510   0.880688 0.898305\n",
            "\n",
            "Gradien Boosting Model Performance Metrics\n",
            "Configuration Name:  ADASYN\n",
            " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
            "Training  0.960159  0.960070 0.960115   0.960127 0.996383\n",
            "    Test  0.893617  0.851917 0.844207   0.865900 0.900515\n",
            "\n",
            "Gradien Boosting Model Performance Metrics\n",
            "Configuration Name:  CondensedNN\n",
            " Dataset  Accuracy  F1 Score  Recall  Precision  AUC-ROC\n",
            "Training  0.890000  0.875327 0.85119   0.911937 0.978374\n",
            "    Test  0.851064  0.792344 0.79287   0.801924 0.823960\n",
            "\n",
            "Gradien Boosting Model Performance Metrics\n",
            "Configuration Name:  Tomek Links\n",
            " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
            "Training  0.931900  0.923321 0.920080   0.926766 0.990627\n",
            "    Test  0.893617  0.843243 0.844207   0.851058 0.890924\n",
            "\n",
            "Gradien Boosting Model Performance Metrics\n",
            "Configuration Name:  Random Oversampling\n",
            " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
            "Training  0.934959  0.934635 0.934959   0.934878 0.992874\n",
            "    Test  0.808511  0.768019 0.795722   0.760079 0.887108\n",
            "\n",
            "Gradien Boosting Model Performance Metrics\n",
            "Configuration Name:  Random Undersampling\n",
            " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
            "Training  0.934524  0.935239 0.934524   0.940546 0.995057\n",
            "    Test  0.872340  0.823819 0.832086   0.823912 0.897504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extra Trees with K-Fold, Oversampling, Undersampling, Randomsampling"
      ],
      "metadata": {
        "id": "EtjUT-NQw64A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "configurations = []\n",
        "configurations.append(('Original Data', X_train, X_test, y_train))\n",
        "\n",
        "# Step 2: Normalize the data\n",
        "scaler = MinMaxScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "X_train_normalized = scaler.transform(X_train)\n",
        "X_test_normalized = scaler.transform(X_test)\n",
        "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
        "\n",
        "# applying k-fold cv with Extra Trees Classifier\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# ExtraTrees classifier\n",
        "etc = GradientBoostingClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "cv_score = cross_val_score(etc, X_normalized, y, cv=kfold, scoring='accuracy').mean()\n",
        "cv_score = float(cv_score)\n",
        "print(\"\\nApplying K-Fold cross validation Extra Trees Classifier's score is: \", cv_score)\n",
        "\n",
        "# applying oversampling Smote & ADASYN\n",
        "smote = SMOTE(random_state=42)\n",
        "adasyn = ADASYN(random_state=42)\n",
        "X_train_resample_smote, y_train_resample_smote = smote.fit_resample(X_train_normalized, y_train)\n",
        "X_train_resample_adasyn, y_train_resample_adasyn = adasyn.fit_resample(X_train_normalized, y_train)\n",
        "configurations.append(('SMOTE', X_train_resample_smote, X_test_normalized, y_train_resample_smote))\n",
        "configurations.append(('ADASYN', X_train_resample_adasyn, X_test_normalized, y_train_resample_adasyn))\n",
        "\n",
        "# applying undersampling CNN & Tomek Links\n",
        "cnn = CondensedNearestNeighbour(random_state=42)\n",
        "tomek = TomekLinks()\n",
        "X_train_resample_cnn, y_train_resample_cnn = cnn.fit_resample(X_train_normalized, y_train)\n",
        "X_train_resample_tomek, y_train_resample_tomek = tomek.fit_resample(X_train_normalized, y_train)\n",
        "configurations.append(('CondensedNN', X_train_resample_cnn, X_test_normalized, y_train_resample_cnn))\n",
        "configurations.append(('Tomek Links', X_train_resample_tomek, X_test_normalized, y_train_resample_tomek))\n",
        "\n",
        "# applying randomsampling Randomoversampling & Randomundersampling\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "X_train_resample_ros, y_train_resample_ros = ros.fit_resample(X_train_normalized, y_train)\n",
        "X_train_resample_rus, y_train_resample_rus = rus.fit_resample(X_train_normalized, y_train)\n",
        "configurations.append(('Random Oversampling', X_train_resample_ros, X_test_normalized, y_train_resample_ros))\n",
        "configurations.append(('Random Undersampling', X_train_resample_rus, X_test_normalized, y_train_resample_rus))\n",
        "\n",
        "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
        "  etc.fit(X_train_cfg, y_train_cfg)\n",
        "\n",
        "  y_train_et = etc.predict(X_train_cfg)\n",
        "  y_test_et = etc.predict(X_test_cfg)\n",
        "  y_train_et_proba = etc.predict_proba(X_train_cfg)\n",
        "  y_test_et_proba = etc.predict_proba(X_test_cfg)\n",
        "\n",
        "  metrics_dict = {\n",
        "        \"Dataset\": [\"Training\", \"Test\"],\n",
        "        \"Accuracy\": [\n",
        "            metrics.accuracy_score(y_train_cfg, y_train_et),\n",
        "            metrics.accuracy_score(y_test, y_test_et),\n",
        "        ],\n",
        "        \"F1 Score\": [\n",
        "            metrics.f1_score(y_train_cfg, y_train_et, average='macro'),\n",
        "            metrics.f1_score(y_test, y_test_et, average='macro'),\n",
        "        ],\n",
        "        \"Recall\": [\n",
        "            metrics.recall_score(y_train_cfg, y_train_et, average='macro'),\n",
        "            metrics.recall_score(y_test, y_test_et, average='macro'),\n",
        "        ],\n",
        "        \"Precision\": [\n",
        "            metrics.precision_score(y_train_cfg, y_train_et, average='macro'),\n",
        "            metrics.precision_score(y_test, y_test_et, average='macro'),\n",
        "        ],\n",
        "        \"AUC-ROC\": [\n",
        "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_et_proba, multi_class='ovr', average='macro'),\n",
        "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_et_proba, multi_class='ovr', average='macro'),\n",
        "        ]\n",
        "    }\n",
        "\n",
        "  df_metrics = pd.DataFrame(metrics_dict)\n",
        "  print(\"\\nExtraTrees Model Performance Metrics\")\n",
        "  print(\"Configuration Name: \", name)\n",
        "  print(df_metrics.to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01gypP_5xEKE",
        "outputId": "eed3e8ae-9a32-4f97-e727-944f271579eb"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Applying K-Fold cross validation Extra Trees Classifier's score is:  0.9092460881934565\n",
            "\n",
            "ExtraTrees Model Performance Metrics\n",
            "Configuration Name:  Original Data\n",
            " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
            "Training  0.932143  0.923808 0.920645   0.927169 0.990717\n",
            "    Test  0.893617  0.843243 0.844207   0.851058 0.890514\n",
            "\n",
            "ExtraTrees Model Performance Metrics\n",
            "Configuration Name:  Normalized Data\n",
            " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
            "Training  0.932143  0.923808 0.920645   0.927169 0.990717\n",
            "    Test  0.893617  0.843243 0.844207   0.851058 0.890514\n",
            "\n",
            "ExtraTrees Model Performance Metrics\n",
            "Configuration Name:  SMOTE\n",
            " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
            "Training  0.961382  0.961429 0.961382   0.961621 0.996486\n",
            "    Test  0.914894  0.876705 0.874510   0.880688 0.898305\n",
            "\n",
            "ExtraTrees Model Performance Metrics\n",
            "Configuration Name:  ADASYN\n",
            " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
            "Training  0.960159  0.960070 0.960115   0.960127 0.996383\n",
            "    Test  0.893617  0.851917 0.844207   0.865900 0.900515\n",
            "\n",
            "ExtraTrees Model Performance Metrics\n",
            "Configuration Name:  CondensedNN\n",
            " Dataset  Accuracy  F1 Score  Recall  Precision  AUC-ROC\n",
            "Training  0.890000  0.875327 0.85119   0.911937 0.978374\n",
            "    Test  0.851064  0.792344 0.79287   0.801924 0.823960\n",
            "\n",
            "ExtraTrees Model Performance Metrics\n",
            "Configuration Name:  Tomek Links\n",
            " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
            "Training  0.931900  0.923321 0.920080   0.926766 0.990627\n",
            "    Test  0.893617  0.843243 0.844207   0.851058 0.890924\n",
            "\n",
            "ExtraTrees Model Performance Metrics\n",
            "Configuration Name:  Random Oversampling\n",
            " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
            "Training  0.934959  0.934635 0.934959   0.934878 0.992874\n",
            "    Test  0.808511  0.768019 0.795722   0.760079 0.887108\n",
            "\n",
            "ExtraTrees Model Performance Metrics\n",
            "Configuration Name:  Random Undersampling\n",
            " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
            "Training  0.934524  0.935239 0.934524   0.940546 0.995057\n",
            "    Test  0.872340  0.823819 0.832086   0.823912 0.897504\n"
          ]
        }
      ]
    }
  ]
}