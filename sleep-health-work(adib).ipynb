{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6491929,"sourceType":"datasetVersion","datasetId":3321433}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.feature_selection import mutual_info_regression\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport warnings\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.feature_selection import SelectKBest, f_classif, RFECV, RFE\nfrom sklearn.decomposition import PCA\nfrom sklearn.ensemble import  RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn import metrics\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-25T15:21:35.782863Z","iopub.execute_input":"2025-08-25T15:21:35.783220Z","iopub.status.idle":"2025-08-25T15:21:35.790746Z","shell.execute_reply.started":"2025-08-25T15:21:35.783196Z","shell.execute_reply":"2025-08-25T15:21:35.789923Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/sleep-health-and-lifestyle-dataset/Sleep_health_and_lifestyle_dataset.csv\")\n\ndf['Sleep Disorder'] = df['Sleep Disorder'].fillna(\"okay\")\n\n\n\nimport pandas as pd\n\ndf=df.drop(['Person ID'],axis=1)\n# One-hot encode specific columns\ndf = pd.get_dummies(df, columns=['Gender', 'Occupation', 'BMI Category','Blood Pressure'], drop_first=False)\n\n\n\n\nfrom sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\ndf['Sleep Disorder'] = le.fit_transform(df['Sleep Disorder'])\n\nfrom sklearn.model_selection import train_test_split\ntarget_col='Sleep Disorder'\nX = df.drop(columns=[target_col])\ny = df[target_col]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T15:21:37.820772Z","iopub.execute_input":"2025-08-25T15:21:37.821128Z","iopub.status.idle":"2025-08-25T15:21:37.840027Z","shell.execute_reply.started":"2025-08-25T15:21:37.821098Z","shell.execute_reply":"2025-08-25T15:21:37.839104Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"ML_Model = []\nML_Config = []\naccuracy = []\nf1_score = []\nrecall = []\nprecision = []\nauc_roc = []  # Adding a holder for AUC-ROC\n\n\ndef storeResults(model, config, a, b, c, d, e):\n    \"\"\"\n    Store model performance results\n    \n    Parameters:\n    model: Name of the ML model\n    config: Configuration name (preprocessing steps applied)\n    a: Accuracy score\n    b: F1 score\n    c: Recall score\n    d: Precision score\n    e: AUC-ROC score\n    \"\"\"\n    ML_Model.append(model)\n    ML_Config.append(config)\n    accuracy.append(round(a, 6))\n    f1_score.append(round(b, 6))\n    recall.append(round(c, 6))\n    precision.append(round(d, 6))\n    auc_roc.append(round(e, 6))\n\n\nconfigurations = []\nconfigurations.append(('Original Data', X_train, X_test, y_train))\n\n# Step 2: Normalize the data\nscaler = MinMaxScaler()\nX_train_normalized = scaler.fit_transform(X_train)\nX_test_normalized = scaler.transform(X_test)\nconfigurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n\n\n\n# Step 4: SVM + GridSearchCV\nprint(\"\\n=== SVM Model Performance with Hyperparameter Tuning ===\")\n\nparam_grid = {\n    'C': [100],\n    'gamma': ['auto'],\n    'kernel': ['sigmoid'],\n    'degree': [2],\n    'coef0': [0.0]\n}\n\nfor name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n    print(f\"\\nRunning SVM with {name} configuration...\")\n    svc = GridSearchCV(SVC(probability=True), param_grid, cv=2, n_jobs=-1, verbose=2)\n    svc.fit(X_train_cfg, y_train_cfg)\n\n    y_train_svc = svc.predict(X_train_cfg)\n    y_test_svc = svc.predict(X_test_cfg)\n    y_train_svc_proba = svc.predict_proba(X_train_cfg)\n    y_test_svc_proba = svc.predict_proba(X_test_cfg)\n\n    metrics_dict = {\n        \"Dataset\": [\"Training\", \"Test\"],\n        \"Accuracy\": [\n            metrics.accuracy_score(y_train_cfg, y_train_svc),\n            metrics.accuracy_score(y_test, y_test_svc),\n        ],\n        \"F1 Score\": [\n            metrics.f1_score(y_train_cfg, y_train_svc, average='macro'),\n            metrics.f1_score(y_test, y_test_svc, average='macro'),\n        ],\n        \"Recall\": [\n            metrics.recall_score(y_train_cfg, y_train_svc, average='macro'),\n            metrics.recall_score(y_test, y_test_svc, average='macro'),\n        ],\n        \"Precision\": [\n            metrics.precision_score(y_train_cfg, y_train_svc, average='macro'),\n            metrics.precision_score(y_test, y_test_svc, average='macro'),\n        ],\n        \"AUC-ROC\": [\n            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_svc_proba, multi_class='ovr', average='macro'),\n            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_svc_proba, multi_class='ovr', average='macro'),\n        ]\n    }\n\n    df_metrics = pd.DataFrame(metrics_dict)\n    print(\"\\nSupport Vector Machine Model Performance Metrics\")\n    print(df_metrics.to_string(index=False))\n\n    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_svc_proba, multi_class='ovr', average='macro')\n    storeResults(\n        'Support Vector Machine 99',\n        name,\n        metrics.accuracy_score(y_test, y_test_svc),\n        metrics.f1_score(y_test, y_test_svc, average='macro'),\n        metrics.recall_score(y_test, y_test_svc, average='macro'),\n        metrics.precision_score(y_test, y_test_svc, average='macro'),\n        auc_score\n    )\n\n    print(\"Best hyperparameters found by GridSearchCV:\")\n    print(svc.best_params_)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T15:23:20.896289Z","iopub.execute_input":"2025-08-25T15:23:20.896634Z","iopub.status.idle":"2025-08-25T15:23:21.055284Z","shell.execute_reply.started":"2025-08-25T15:23:20.896601Z","shell.execute_reply":"2025-08-25T15:23:21.054406Z"}},"outputs":[{"name":"stdout","text":"\n=== SVM Model Performance with Hyperparameter Tuning ===\n\nRunning SVM with Original Data configuration...\nFitting 2 folds for each of 1 candidates, totalling 2 fits\n\nSupport Vector Machine Model Performance Metrics\n Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\nTraining  0.585714  0.246246 0.333333   0.195238      0.5\n    Test  0.585106  0.246085 0.333333   0.195035      0.5\nBest hyperparameters found by GridSearchCV:\n{'C': 100, 'coef0': 0.0, 'degree': 2, 'gamma': 'auto', 'kernel': 'sigmoid'}\n\nRunning SVM with Normalized Data configuration...\nFitting 2 folds for each of 1 candidates, totalling 2 fits\n\nSupport Vector Machine Model Performance Metrics\n Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\nTraining  0.932143  0.918933 0.909378   0.930465 0.950973\n    Test  0.914894  0.894070 0.907337   0.882984 0.950821\nBest hyperparameters found by GridSearchCV:\n{'C': 100, 'coef0': 0.0, 'degree': 2, 'gamma': 'auto', 'kernel': 'sigmoid'}\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
